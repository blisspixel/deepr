# Deepr

**Knowledge Is Power, Automate It**

A modular research-as-a-service platform that automates complex research tasks, generating structured, citation-backed reports using OpenAI's Deep Research API and Azure OpenAI.

Deepr is a production-ready research pipeline supporting both CLI and web interfaces, with local development and cloud deployment options. Built on OpenAI's Deep Research API (o3-deep-research, o4-mini-deep-research), it automates multi-step research with deep synthesis, web search integration, and structured output in multiple formats.

## Current Status

**Version 2.x** - Major architectural refactoring in progress

- v1.x (deepr.py, manager.py) - Functional but monolithic, deprecated
- v2.x - Modular architecture with provider abstraction, queue system, cost controls

See [docs/development/IMPLEMENTATION_STATUS.md](docs/development/IMPLEMENTATION_STATUS.md) for detailed status.

## Purpose

Deepr accelerates complex research tasks in domains such as:

- **Competitive Intelligence** - Market research, competitor analysis, product trends
- **Regulatory Monitoring** - Legal and regulatory change tracking
- **Technical Due Diligence** - Architecture analysis, security practices, compliance
- **Policy Research** - Strategic initiatives, business narratives, policy decisions

Designed for automation, consistency, and scalability - from ad hoc investigations to production-scale pipelines.

## Key Features

### Multi-Cloud Provider Support
- OpenAI Deep Research API
- Azure OpenAI Deep Research API
- Pluggable provider architecture

### Intelligent Queue System
- Local: SQLite-based queue with priority support
- Cloud: Azure Service Bus for enterprise scale
- Atomic job claiming and status tracking

### Cost Management
- Per-job, daily, and monthly cost limits
- Real-time cost estimation before job submission
- Safe test prompts for development
- Token usage tracking and reporting

### Storage Backends
- Local: Filesystem-based storage
- Cloud: Azure Blob Storage integration
- Automatic result archival

### Multiple Output Formats
- Markdown (.md)
- Word documents (.docx)
- Plain text (.txt)
- JSON (.json)
- PDF (planned)

### Research-as-a-Service
- REST API for programmatic access
- Web interface for visual management
- Webhook callbacks for async results
- Batch processing support

## Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/blisspixel/deepr.git
cd deepr

# Install dependencies
pip install -r requirements.txt

# Setup local environment
python scripts/setup_local.py
```

### Configuration

Edit `.env` with your credentials:

```bash
# Provider (openai or azure)
DEEPR_PROVIDER=openai
OPENAI_API_KEY=sk-...

# Or for Azure
# DEEPR_PROVIDER=azure
# AZURE_OPENAI_API_KEY=your_key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Cost limits (USD)
DEEPR_MAX_COST_PER_JOB=10.00
DEEPR_MAX_COST_PER_DAY=100.00
DEEPR_MAX_COST_PER_MONTH=1000.00
```

### Basic Usage (v1.x - Deprecated)

```bash
# Interactive mode
python deepr.py

# One-off research
python deepr.py --research "your research prompt here"

# Batch processing
python deepr.py --batch-file queue.txt

# Cost-sensitive mode (cheaper model)
python deepr.py --cost-sensitive --research "your prompt"
```

### v2.x Usage (In Development)

```bash
# Check system status
python -m deepr.cli status

# Submit research job
python -m deepr.cli research "your research prompt"

# List jobs
python -m deepr.cli list

# Get job details
python -m deepr.cli get <job_id>

# Start worker (processes queue)
python -m deepr.cli worker
```

## Architecture

### Core Components

```
deepr/
├── providers/          # OpenAI and Azure provider implementations
├── storage/            # Local and blob storage backends
├── queue/              # SQLite and Azure Service Bus queues
├── core/               # Business logic (costs, research, results)
├── config.py           # Configuration management
└── cli.py              # Command-line interface
```

### Provider Abstraction

All API calls go through provider interface supporting:
- Job submission with cost estimation
- Status polling
- Result retrieval
- Job cancellation

### Queue System

Jobs flow through a priority queue:
1. Submit job with prompt and configuration
2. Cost estimator validates against limits
3. Job enqueued with priority
4. Worker claims and processes job
5. Results stored via storage backend

### Storage Backend

Configurable storage for results:
- **Local**: `results/` directory with JSON/MD/DOCX files
- **Blob**: Azure Blob Storage with container organization

## Cost Management

Deepr includes comprehensive cost controls:

```python
# Cost estimation before submission
from deepr.core.costs import CostEstimator

estimate = CostEstimator.estimate_cost(
    prompt="Your research prompt",
    model="o4-mini-deep-research",
    enable_web_search=True
)

print(f"Estimated cost: ${estimate.expected_cost:.2f}")
```

**Safety features:**
- Pre-submission cost estimates
- Configurable per-job limits
- Daily and monthly budget caps
- Test prompts for safe development

## Scripts

### Local Environment

```bash
# Setup
python scripts/setup_local.py

# Cleanup
python scripts/cleanup_local.py
python scripts/cleanup_local.py --all  # Delete all data
```

### Azure Environment

```bash
# Setup (creates Storage + Service Bus)
python scripts/setup_azure.py

# Teardown
python scripts/destroy_azure.py
python scripts/destroy_azure.py --delete-resource-group  # Full cleanup
```

### Job Management

```bash
# Cancel all jobs (PowerShell)
.\scripts\cancel_all_jobs.ps1

# Convert legacy reports
python scripts/convert_legacy_report.py input.txt output.md
```

See [scripts/README.md](scripts/README.md) for full documentation.

## Configuration

Configuration via environment variables or `.env` file:

### Provider Settings
- `DEEPR_PROVIDER` - Provider type (openai, azure)
- `OPENAI_API_KEY` - OpenAI API key
- `AZURE_OPENAI_API_KEY` - Azure OpenAI key
- `AZURE_OPENAI_ENDPOINT` - Azure endpoint URL

### Storage Settings
- `DEEPR_STORAGE` - Storage backend (local, blob)
- `AZURE_STORAGE_CONNECTION_STRING` - Azure storage connection
- `DEEPR_RESULTS_DIR` - Local results directory (default: results/)

### Queue Settings
- `DEEPR_QUEUE` - Queue backend (local, azure)
- `DEEPR_QUEUE_DB_PATH` - SQLite database path
- `AZURE_SERVICE_BUS_CONNECTION_STRING` - Azure Service Bus connection

### Cost Limits
- `DEEPR_MAX_COST_PER_JOB` - Maximum per-job cost (USD)
- `DEEPR_MAX_COST_PER_DAY` - Maximum daily cost (USD)
- `DEEPR_MAX_COST_PER_MONTH` - Maximum monthly cost (USD)

### Model Settings
- `DEEPR_DEFAULT_MODEL` - Default model (o3-deep-research, o4-mini-deep-research)
- `DEEPR_ENABLE_WEB_SEARCH` - Enable web search by default (true/false)

## Output Formats

All research results saved in multiple formats:

```
results/
├── <job_id>.json       # Structured data
├── <job_id>.md         # Markdown report
├── <job_id>.docx       # Word document
└── <job_id>.txt        # Plain text
```

Word documents include professional formatting with headings, bullet points, and semantic styles.

## Job Logging

All jobs tracked in `job_log.jsonl`:

```json
{
  "timestamp": "2025-10-07T12:34:56Z",
  "job_id": "f6e2e738",
  "prompt": "Research quantum computing impact on cryptography",
  "status": "completed",
  "model": "o4-mini-deep-research",
  "estimated_cost": 2.50,
  "actual_cost": 2.35
}
```

## Requirements

- Python 3.9+
- OpenAI API key or Azure OpenAI credentials
- Internet access

**Optional:**
- Azure CLI (for cloud deployment)
- Ngrok (for v1.x webhook support)

## Dependencies

```bash
pip install -r requirements.txt
```

Core dependencies:
- openai
- pydantic
- python-dotenv
- aiofiles
- python-docx
- flask (for web interface)

## Documentation

- [Quick Start](docs/QUICKSTART_V2.md) - Get started with v2
- [Architecture Vision](docs/development/architecture-vision.md) - System design
- [Migration Guide](docs/development/migration-guide.md) - v1 to v2 migration
- [API Reference](docs/api/azure-deep-research.md) - Deep Research API details
- [Scripts Guide](scripts/README.md) - Utility scripts documentation

## Roadmap

### Version 2.0 (In Progress)
- [x] Provider abstraction (OpenAI + Azure)
- [x] Storage abstraction (Local + Blob)
- [x] Queue system (SQLite + Service Bus)
- [x] Cost estimation and controls
- [x] Configuration management
- [ ] CLI integration with new architecture
- [ ] Worker process implementation
- [ ] Web interface (Flask + templates)
- [ ] REST API endpoints
- [ ] Real provider integration tests

### Version 2.1 (Planned)
- [ ] Azure deployment guides
- [ ] Docker containerization
- [ ] Kubernetes manifests
- [ ] Authentication and authorization
- [ ] Multi-tenancy support
- [ ] Usage analytics dashboard
- [ ] PDF output support

### Version 2.2 (Future)
- [ ] Multi-user web interface
- [ ] Real-time job monitoring
- [ ] Advanced queue management UI
- [ ] Cost analytics and reporting
- [ ] Custom output templates
- [ ] Webhook integrations
- [ ] API rate limiting
- [ ] Job scheduling (cron-style)

### Version 3.0 (Vision)
- [ ] Multi-region deployment
- [ ] High availability configuration
- [ ] Advanced caching strategies
- [ ] Result deduplication
- [ ] Machine learning cost prediction
- [ ] Automated report quality scoring
- [ ] Enterprise SSO integration
- [ ] Advanced audit logging

## Testing

```bash
# Run all tests
pytest

# Cost estimation tests (local only)
pytest tests/unit/test_costs.py -v

# Queue tests (local only)
pytest tests/unit/test_queue/test_local_queue.py -v

# Run with coverage
pytest --cov=deepr tests/
```

All tests run locally without API calls to avoid costs.

## Contributing

Contributions welcome. Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## License

See [LICENSE](LICENSE) for details.

## Support

- Issues: https://github.com/blisspixel/deepr/issues
- Documentation: [docs/](docs/)

## Warning

Deep Research API calls can be expensive. Always:
- Set appropriate cost limits
- Use cost estimation before submission
- Start with o4-mini-deep-research for testing
- Monitor your usage and spending
- Use cheap test prompts during development

Example: A complex research query can cost $5-50 depending on model, web search usage, and output length.
